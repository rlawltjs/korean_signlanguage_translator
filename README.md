# Korean Sign Language Recognition System
# í•œêµ­ ìˆ˜ì–´ ì¸ì‹ ì‹œìŠ¤í…œ

AIHub ë°ì´í„°ì…‹ì„ í™œìš©í•œ í•œêµ­ ìˆ˜ì–´ ì¸ì‹ ë° ì‹¤ì‹œê°„ ë²ˆì—­ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë°ì´í„° ì „ì²˜ë¦¬ë¶€í„° ëª¨ë¸ í›ˆë ¨, ì‹¤ì‹œê°„ ì„œë²„ ë°°í¬ê¹Œì§€ ì „ì²´ íŒŒì´í”„ë¼ì¸ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¬ ë°ëª¨ ì˜ìƒ

### ì‹¤ì‹œê°„ ìˆ˜ì–´ ì¸ì‹ ì˜ˆì‹œ

[Click here to view the video](https://github.com/user-attachments/assets/69441a40-d08f-4c6b-b093-d7609ce7eed6)

*ì‹¤ì‹œê°„ ì›¹ìº ì„ í†µí•œ í•œêµ­ ìˆ˜ì–´ ì¸ì‹ ë° ë²ˆì—­*

## ğŸ“‹ ëª©ì°¨

- [í”„ë¡œì íŠ¸ ê°œìš”](#í”„ë¡œì íŠ¸-ê°œìš”)
- [ì‹œìŠ¤í…œ êµ¬ì¡°](#ì‹œìŠ¤í…œ-êµ¬ì¡°)
- [ìš”êµ¬ì‚¬í•­](#ìš”êµ¬ì‚¬í•­)
- [ì„¤ì¹˜ ë°©ë²•](#ì„¤ì¹˜-ë°©ë²•)
- [ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬](#ë°ì´í„°-ì¤€ë¹„-ë°-ì „ì²˜ë¦¬)
- [ëª¨ë¸ í›ˆë ¨](#ëª¨ë¸-í›ˆë ¨)
- [ì„œë²„ ë°°í¬ ë° ì‹¤í–‰](#ì„œë²„-ë°°í¬-ë°-ì‹¤í–‰)
- [ì‚¬ìš© ë°©ë²•](#ì‚¬ìš©-ë°©ë²•)
- [ë¬¸ì œ í•´ê²°](#ë¬¸ì œ-í•´ê²°)
- [ê¸°ì—¬ ë°©ë²•](#ê¸°ì—¬-ë°©ë²•)

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

ë³¸ ì‹œìŠ¤í…œì€ ì²­ê° ì¥ì• ì¸ê³¼ ì¼ë°˜ì¸ ê°„ì˜ ì˜ì‚¬ì†Œí†µ ì¥ë²½ì„ í•´ì†Œí•˜ê¸° ìœ„í•œ AI ê¸°ë°˜ í•œêµ­ ìˆ˜ì–´ ì¸ì‹ ë° ë²ˆì—­ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•

#### ğŸ¤– ëª¨ë¸ ê°œë°œ (model í´ë”)
- **AIHub í•œêµ­ ìˆ˜ì–´ ë°ì´í„°ì…‹** í™œìš© (536,000 ìˆ˜ì–´ì˜ìƒ í´ë¦½)
- **OpenHands ëª¨ë¸** ê¸°ë°˜ Transformer ì•„í‚¤í…ì²˜
- **MediaPipe** ê¸°ë°˜ ì† ë° í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ
- **ì‹œí€€ìŠ¤-íˆ¬-ì‹œí€€ìŠ¤** í•™ìŠµìœ¼ë¡œ ì—°ì† ìˆ˜ì–´ ì¸ì‹
- **Intel GPU ìµœì í™”** ì§€ì› (Intel Extension for PyTorch)

#### ğŸŒ ì‹¤ì‹œê°„ ì„œë²„ (server í´ë”)
- **ì‹¤ì‹œê°„ ì›¹ìº ** ê¸°ë°˜ ìˆ˜ì–´ ì¸ì‹ ë° ë²ˆì—­
- **COCO Wholebody** 133ê°œ í‚¤í¬ì¸íŠ¸ í¬ì¦ˆ ì¶”ì •
- **Flask ê¸°ë°˜** ì›¹ ì¸í„°í˜ì´ìŠ¤ ë° REST API
- **YOLOv11** ê¸°ë°˜ ì‚¬ëŒ ê²€ì¶œ
- **ë©€í‹°í´ë¼ì´ì–¸íŠ¸** ì§€ì›

### ì§€ì› ê¸°ëŠ¥

- ìˆ˜ì–´ ë‹¨ì–´ ë° ë¬¸ì¥ ì¸ì‹ (2,000ê°œ ìˆ˜ì–´ë¬¸ì¥, 3,000ê°œ ìˆ˜ì–´ë‹¨ì–´)
- ì‹¤ì‹œê°„ ì† ëœë“œë§ˆí¬ ì¶”ì¶œ (21ê°œ í¬ì¸íŠ¸ Ã— 2ì† = 42ê°œ í¬ì¸íŠ¸)
- ìƒì²´ í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ (6ê°œ ì£¼ìš” í¬ì¸íŠ¸)
- ë‹¤ì¤‘ ê°ë„ ë°ì´í„° ì²˜ë¦¬ (5ê°œ ê°ë„)
- ë‹¤ì¤‘ í™”ì ì§€ì› (16ëª… í™”ì)
- ì›¹ ê¸°ë°˜ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ì œì–´

## ğŸ— ì‹œìŠ¤í…œ êµ¬ì¡°

```
korean_sign_language_recognition/
â”œâ”€â”€ model/                          # ëª¨ë¸ ê°œë°œ ë° í›ˆë ¨
â”‚   â”œâ”€â”€ main.py                     # ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
â”‚   â”œâ”€â”€ openhands_finetuner.py      # ëª¨ë¸ ì •ì˜ ë° í›ˆë ¨
â”‚   â”œâ”€â”€ data_preprocessor.py        # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ test_setup.py               # ì„¤ì¹˜ í™˜ê²½ í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ requirements-basic.txt      # ê¸°ë³¸ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ requirements.txt            # ì „ì²´ íŒ¨í‚¤ì§€
â”‚   â”œâ”€â”€ aihub_data/                 # AIHub ì›ë³¸ ë°ì´í„°
â”‚   â”œâ”€â”€ processed_data/             # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”‚   â””â”€â”€ models/                     # í›ˆë ¨ëœ ìˆ˜ì–´ ì¸ì‹ ëª¨ë¸
â”‚
â”œâ”€â”€ server/                         # ì‹¤ì‹œê°„ ì„œë²„ ë° í´ë¼ì´ì–¸íŠ¸
â”‚   â”œâ”€â”€ model.pt                    # í¬ì¦ˆ ì¶”ì • ëª¨ë¸
â”‚   â”œâ”€â”€ enhanced_pose_server.py     # í†µí•© í¬ì¦ˆ/ìˆ˜ì–´ ì„œë²„
â”‚   â”œâ”€â”€ enhanced_webcam_client.py   # ì›¹ìº  í´ë¼ì´ì–¸íŠ¸
â”‚   â”œâ”€â”€ flask_web_interface.py      # Flask ì›¹ ì¸í„°í˜ì´ìŠ¤
â”‚   â”œâ”€â”€ class_to_idx.py             # í´ë˜ìŠ¤ ë§¤í•‘ ì¶”ì¶œ
â”‚   â”œâ”€â”€ templates/                  # HTML í…œí”Œë¦¿
â”‚   â””â”€â”€ configs/                    # MMPose ì„¤ì • íŒŒì¼
â”‚
â””â”€â”€ README.md
```

### ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

#### ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸
```
AIHub ì›ë³¸ ë°ì´í„° â†’ ì „ì²˜ë¦¬ â†’ íŠ¹ì§• ì¶”ì¶œ â†’ ëª¨ë¸ í›ˆë ¨ â†’ í‰ê°€ â†’ ë°°í¬
```

#### ì‹¤ì‹œê°„ ì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜
```
ì›¹ìº  ì…ë ¥ â†’ YOLOv11 ì‚¬ëŒê²€ì¶œ â†’ RTMW í¬ì¦ˆì¶”ì • â†’ MediaPipe íŠ¹ì§•ì¶”ì¶œ â†’ Transformer ìˆ˜ì–´ì¸ì‹ â†’ ê²°ê³¼ ë°˜í™˜
```

## ğŸ›  ìš”êµ¬ì‚¬í•­

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

- **ë©”ëª¨ë¦¬**: ìµœì†Œ 16GB RAM (32GB ê¶Œì¥)
- **GPU**: Intel GPU (Arc, Iris Xe) ë˜ëŠ” NVIDIA GPU
- **ì €ì¥ê³µê°„**: ìµœì†Œ 100GB (ì „ì²´ ë°ì´í„°ì…‹ + ëª¨ë¸)
- **ì›¹ìº **: USB ì¹´ë©”ë¼ ë˜ëŠ” ë‚´ì¥ ì¹´ë©”ë¼ (ì„œë²„ ì‹¤í–‰ ì‹œ)

### ì†Œí”„íŠ¸ì›¨ì–´ ìš”êµ¬ì‚¬í•­

- **Python**: 3.8 ì´ìƒ (3.9 ê¶Œì¥)
- **ìš´ì˜ì²´ì œ**: Linux, Windows, macOS
- **Intel GPU ë“œë¼ì´ë²„**: ìµœì‹  ë²„ì „ (Intel GPU ì‚¬ìš© ì‹œ)

### í•µì‹¬ ë¼ì´ë¸ŒëŸ¬ë¦¬

#### ëª¨ë¸ ê°œë°œìš©
- PyTorch (Intel XPU ì§€ì›)
- MediaPipe
- OpenCV
- NumPy, Pandas
- Transformers

#### ì„œë²„ ë°°í¬ìš©
- Flask
- MMPose
- Ultralytics (YOLOv11)
- Intel Extension for PyTorch

## ğŸ“¦ ì„¤ì¹˜ ë°©ë²•

### 1. ì €ì¥ì†Œ í´ë¡  ë° ê¸°ë³¸ ì„¤ì •

```bash
# ì €ì¥ì†Œ í´ë¡ 
git clone <repository-url>
cd korean-sign-language-recognition

# Python í™˜ê²½ ì„¤ì •
conda create -n korean-sign python=3.9
conda activate korean-sign

# ë˜ëŠ” venv ì‚¬ìš©
python -m venv korean-sign
source korean-sign/bin/activate  # Linux/Mac
# korean-sign\Scripts\activate  # Windows
```

### 2. ëª¨ë¸ ê°œë°œ í™˜ê²½ ì„¤ì¹˜

```bash
cd model

# ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ê¶Œì¥)
pip install -r requirements-basic.txt

# ì „ì²´ íŒ¨í‚¤ì§€ ì„¤ì¹˜ (ì„ íƒ)
pip install -r requirements.txt

# Intel GPU ì§€ì› (ì„ íƒ)
chmod +x install_intel_gpu.sh
./install_intel_gpu.sh

# ì„¤ì¹˜ í™•ì¸
python test_setup.py
```

### 3. ì„œë²„ í™˜ê²½ ì„¤ì¹˜

```bash
cd ../server

# ì„œë²„ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt

# MMPose ì„¤ì¹˜
pip install -U openmim
mim install mmengine
mim install mmcv
mim install mmpose

# Intel GPU ì§€ì› (ì„ íƒ)
pip install intel-extension-for-pytorch
```

### 4. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
cd server
mkdir -p models configs/wholebody_2d_keypoint/rtmpose/cocktail14

# RTMW í¬ì¦ˆ ì¶”ì • ëª¨ë¸
wget -P models/ \
  https://download.openmmlab.com/mmpose/v1/wholebody_2d_keypoint/rtmpose/cocktail14/rtmw-l_8xb320-270e_cocktail14-384x288-20231122.pth

# MMPose ì„¤ì • íŒŒì¼
wget -P configs/wholebody_2d_keypoint/rtmpose/cocktail14/ \
  https://raw.githubusercontent.com/open-mmlab/mmpose/main/configs/wholebody_2d_keypoint/rtmpose/cocktail14/rtmw-l_8xb320-270e_cocktail14-384x288.py
```

## ğŸ“Š ë°ì´í„° ì¤€ë¹„ ë° ì „ì²˜ë¦¬

### AIHub ë°ì´í„°ì…‹ êµ¬ì¡°

AIHub í•œêµ­ ìˆ˜ì–´ ë°ì´í„°ì…‹ì„ ë‹¤ìŒê³¼ ê°™ì´ ë°°ì¹˜í•˜ì„¸ìš”:

```
model/aihub_data/
â”œâ”€â”€ sentence_001/
â”‚   â”œâ”€â”€ NIA_SL_SEN0001_REAL01_F.mp4      # ì •ë©´
â”‚   â”œâ”€â”€ NIA_SL_SEN0001_REAL01_F_morpheme.json
â”‚   â”œâ”€â”€ NIA_SL_SEN0001_REAL01_L.mp4      # ì¢Œì¸¡
â”‚   â”œâ”€â”€ NIA_SL_SEN0001_REAL01_L_morpheme.json
â”‚   â”œâ”€â”€ NIA_SL_SEN0001_REAL01_R.mp4      # ìš°ì¸¡
â”‚   â””â”€â”€ ... (ë‹¤ë¥¸ ê°ë„ ë° í™”ì)
â”œâ”€â”€ sentence_002/
â””â”€â”€ ...
```

### ë°ì´í„° ì „ì²˜ë¦¬ ì‹¤í–‰

```bash
cd model

# ë°ì´í„° ì „ì²˜ë¦¬
python main.py preprocess \
    --data_dir ./aihub_data \
    --output_dir ./processed_data \
    --sequence_length 32 \
    --train_ratio 0.8
```

**ì „ì²˜ë¦¬ ê³¼ì •:**
- MP4 ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ
- MediaPipeë¡œ ì† ëœë“œë§ˆí¬ ì¶”ì¶œ (126ì°¨ì›)
- MediaPipeë¡œ í¬ì¦ˆ ëœë“œë§ˆí¬ ì¶”ì¶œ (18ì°¨ì›)
- JSON ì–´ë…¸í…Œì´ì…˜ê³¼ ë™ê¸°í™”
- ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„± ë° ë¶„í•  (train/validation)

### JSON ì–´ë…¸í…Œì´ì…˜ í˜•ì‹

```json
{
    "metaData": {
        "name": "NIA_SL_SEN0001_REAL01_F.mp4",
        "duration": 3.25
    },
    "data": [
        {
            "start": 1.422,
            "end": 2.484,
            "attributes": [{"name": "ë‚˜"}]
        }
    ]
}
```

## ğŸš€ ëª¨ë¸ í›ˆë ¨

### 1. ê¸°ë³¸ í›ˆë ¨

```bash
cd model

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ í›ˆë ¨
python main.py train \
    --processed_data_dir ./processed_data \
    --model_save_dir ./trained_models \
    --batch_size 16 \
    --learning_rate 1e-4 \
    --num_epochs 50
```

### 2. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

```bash
# ì „ì²˜ë¦¬ + í›ˆë ¨ì„ í•œ ë²ˆì—
python main.py pipeline \
    --data_dir ./aihub_data \
    --output_dir ./processed_data \
    --model_save_dir ./trained_models \
    --num_epochs 100 \
    --batch_size 32
```

### 3. ê³ ê¸‰ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¡°ì •

```bash
python main.py train \
    --processed_data_dir ./processed_data \
    --model_save_dir ./trained_models \
    --d_model 512 \        # ëª¨ë¸ ì°¨ì› ì¦ê°€
    --n_heads 16 \         # ì–´í…ì…˜ í—¤ë“œ ì¦ê°€
    --n_layers 12 \        # ë ˆì´ì–´ ìˆ˜ ì¦ê°€
    --batch_size 8 \       # ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ê°ì†Œ
    --learning_rate 5e-5   # í•™ìŠµë¥  ì¡°ì •
```

### ëª¨ë¸ êµ¬ì¡°

```
ì…ë ¥: (batch_size, seq_len, 144)  # MediaPipe íŠ¹ì§•
  â†“
Feature Projection: Linear(144 â†’ d_model)
  â†“
Positional Encoding: Learnable positional embeddings
  â†“
Transformer Encoder: 
  - Multi-Head Attention (n_heads)
  - Feed Forward Network
  - Layer Normalization
  - Dropout (Ã—n_layers)
  â†“
Classification Head: Linear(d_model â†’ vocab_size)
  â†“
ì¶œë ¥: (batch_size, seq_len, vocab_size)  # ìˆ˜ì–´ ë‹¨ì–´ ë¶„ë¥˜
```

## ğŸŒ ì„œë²„ ë°°í¬ ë° ì‹¤í–‰

### 1. í´ë˜ìŠ¤ ë§¤í•‘ ì„¤ì •

```bash
cd server

# í›ˆë ¨ëœ ëª¨ë¸ì—ì„œ í´ë˜ìŠ¤ ì •ë³´ ì¶”ì¶œ
python class_to_idx.py ../model/trained_models/best_model.pt

# ì¶œë ¥ëœ í´ë˜ìŠ¤ ì •ë³´ë¥¼ enhanced_pose_server.pyì— ì¶”ê°€
```

### 2. í†µí•© ì„œë²„ ì‹¤í–‰

```bash
# í¬ì¦ˆ ì¶”ì • + ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì‹¤í–‰
python enhanced_pose_server.py \
  --config ../configs/wholebody_2d_keypoint/rtmpose/cocktail14/rtmw-l_8xb320-270e_cocktail14-384x288.py \
  --checkpoint ../models/rtmw-l_8xb320-270e_cocktail14-384x288-20231122.pth \
  --sign-model ../model/trained_models/best_model.pt \
  --device auto \
  --yolo-model n \
  --port 5000
```

### 3. í´ë¼ì´ì–¸íŠ¸ ì‹¤í–‰

#### ì½˜ì†” í´ë¼ì´ì–¸íŠ¸
```bash
# ì½˜ì†” ë²„ì „ ì‹¤í–‰
python enhanced_webcam_client.py
```

#### ì›¹ ì¸í„°í˜ì´ìŠ¤
```bash
# ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹¤í–‰
python flask_web_interface.py

# ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†
# http://localhost:8000
```

## ğŸ® ì‚¬ìš© ë°©ë²•

### ì½˜ì†” í´ë¼ì´ì–¸íŠ¸ í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤

#### ê¸°ë³¸ ì¡°ì‘
- `q`: ì¢…ë£Œ
- `r`: ë…¹í™” ì‹œì‘/ì¤‘ì§€
- `c`: ì´ë¯¸ì§€ ìº¡ì²˜
- `h`: ë„ì›€ë§ í‘œì‹œ

#### í¬ì¦ˆ ì¶”ì • ì œì–´
- `p`: ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • í† ê¸€
- `s`: ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ í† ê¸€
- `1~5`: í¬ì¦ˆ ì„ê³„ê°’ ì„¤ì • (1.0~5.0)

#### ìˆ˜ì–´ ì¸ì‹ ì œì–´
- `g`: ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ í† ê¸€
- `d`: ìˆ˜ì–´ ì˜ˆì¸¡ í‘œì‹œ í† ê¸€
- `f`: ìˆ˜ì–´ ì˜ˆì¸¡ í‰í™œí™” í† ê¸€
- `6~9`: ìˆ˜ì–´ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.3~0.9)
- `x`: ìˆ˜ì–´ ë²„í¼ í´ë¦¬ì–´

#### ëª¨ë‹ˆí„°ë§
- `t`: ì„œë²„ í†µê³„ ì¡°íšŒ

### ì›¹ ì¸í„°í˜ì´ìŠ¤ ê¸°ëŠ¥

1. **ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼**: ì›¹ìº  ì˜ìƒê³¼ ë¶„ì„ ê²°ê³¼
2. **í¬ì¦ˆ ì¶”ì • ì œì–´**: í¬ì¦ˆ ì¶”ì •, ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ, ì„ê³„ê°’ ì¡°ì ˆ
3. **ìˆ˜ì–´ ì¸ì‹ ì œì–´**: ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ, ê²°ê³¼ í‘œì‹œ, í‰í™œí™”
4. **ë…¹í™” ë° ìº¡ì²˜**: ë¹„ë””ì˜¤ ë…¹í™”, ì´ë¯¸ì§€ ìº¡ì²˜
5. **ì„œë²„ ëª¨ë‹ˆí„°ë§**: ì‹¤ì‹œê°„ í†µê³„ ë° ìƒíƒœ í™•ì¸

### API ì—”ë“œí¬ì¸íŠ¸

#### í¬ì¦ˆ ì¶”ì •
- `POST /estimate_pose`: ì´ë¯¸ì§€ â†’ í¬ì¦ˆ í‚¤í¬ì¸íŠ¸
- `GET /health`: ì„œë²„ ìƒíƒœ í™•ì¸
- `GET /stats`: ì„œë²„ í†µê³„

#### ìˆ˜ì–´ ì¸ì‹
- `POST /sign_recognition`: í†µí•© ìˆ˜ì–´ ì¸ì‹
- `POST /extract_sign_features`: MediaPipe íŠ¹ì§• ì¶”ì¶œ
- `POST /predict_sign`: ë²„í¼ëœ íŠ¹ì§•ìœ¼ë¡œ ìˆ˜ì–´ ì˜ˆì¸¡
- `POST /clear_buffer/<client_id>`: í´ë¼ì´ì–¸íŠ¸ë³„ ë²„í¼ í´ë¦¬ì–´

## ğŸ“ˆ ì„±ëŠ¥ ë° í‰ê°€

### ëª¨ë¸ ì„±ëŠ¥ ì§€í‘œ

#### ì˜ˆìƒ ì„±ëŠ¥
- **ì–´íœ˜ í¬ê¸°**: 500-1000ê°œ ìˆ˜ì–´ ë‹¨ì–´
- **ì‹œí€€ìŠ¤ ì •í™•ë„**: 85-92% (ë°ì´í„°ì…‹ í’ˆì§ˆì— ë”°ë¼)
- **Token-level Accuracy**: ê°œë³„ ìˆ˜ì–´ ë‹¨ì–´ ì •í™•ë„
- **BLEU Score**: ì‹œí€€ìŠ¤ ìœ ì‚¬ë„ ì¸¡ì •

#### ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: 30 FPS (Intel GPU)
- **ì§€ì—°ì‹œê°„**: < 100ms (ë¡œì»¬ ì²˜ë¦¬)
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: 4-8GB (ë°°ì¹˜ í¬ê¸°ì— ë”°ë¼)

### í•˜ë“œì›¨ì–´ë³„ ì„±ëŠ¥ ë¹„êµ

| í•˜ë“œì›¨ì–´ | YOLOv11 FPS | í¬ì¦ˆ ì¶”ì • FPS | ìˆ˜ì–´ ì¸ì‹ ì§€ì—°ì‹œê°„ |
|----------|-------------|---------------|-------------------|
| Intel Arc A770 | 45-60 | 35-40 | ~50ms |
| NVIDIA RTX 3070 | 50-70 | 40-45 | ~40ms |
| Intel i7 CPU | 15-25 | 10-15 | ~200ms |

### ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

```bash
# TensorBoard ì‹¤í–‰ (í›ˆë ¨ ì‹œ)
cd model
tensorboard --logdir ./trained_models/logs

# ì‹¤ì‹œê°„ ì„œë²„ ë¡œê·¸
tail -f korean_sign_recognition.log
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ëª¨ë¸ í›ˆë ¨ ê´€ë ¨

#### Intel GPU ì¸ì‹ ì‹¤íŒ¨
```bash
# Intel GPU ë“œë¼ì´ë²„ í™•ì¸
intel_gpu_top

# OneAPI í™˜ê²½ ì„¤ì •
source /opt/intel/oneapi/setvars.sh

# Pythonì—ì„œ í™•ì¸
python -c "import torch; print('XPU available:', torch.xpu.is_available())"
```

#### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ê°ì†Œ
python main.py train --batch_size 8

# ì‹œí€€ìŠ¤ ê¸¸ì´ ê°ì†Œ
python main.py train --sequence_length 16

# ëª¨ë¸ í¬ê¸° ê°ì†Œ
python main.py train --d_model 128 --n_layers 4
```

#### MediaPipe ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (Ubuntu)
sudo apt-get install libgl1-mesa-glx

# macOS
brew install opencv

# MediaPipe ì¬ì„¤ì¹˜
pip uninstall mediapipe
pip install mediapipe --no-cache-dir
```

### ì„œë²„ ì‹¤í–‰ ê´€ë ¨

#### ì¹´ë©”ë¼ ì ‘ê·¼ ì˜¤ë¥˜
```python
# ì¹´ë©”ë¼ ì¸ë±ìŠ¤ ë³€ê²½
self.cap = cv2.VideoCapture(1)  # 0 â†’ 1ë¡œ ë³€ê²½
```

#### ì„œë²„ ì—°ê²° ì‹¤íŒ¨
```bash
# ë°©í™”ë²½ ì„¤ì • í™•ì¸
sudo ufw allow 5000

# ë‹¤ë¥¸ í¬íŠ¸ ì‚¬ìš©
python enhanced_pose_server.py --port 5001
```

#### ì„±ëŠ¥ ìµœì í™”
```python
# FPS ì¡°ì ˆ
self.fps = 5  # ë‚®ì€ FPSë¡œ ì„¤ì •

# ì„ê³„ê°’ ì¡°ì ˆ
self.pose_threshold = 3.0  # ë†’ì€ ì„ê³„ê°’
```

### GPU ê´€ë ¨ ë¬¸ì œ

#### CUDA vs Intel GPU ì¶©ëŒ
```bash
# CUDA ë¹„í™œì„±í™”
export CUDA_VISIBLE_DEVICES=""

# Intel GPU ê°•ì œ ì‚¬ìš©
export USE_INTEL_GPU=1
```

#### ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
```bash
# Intel GPU ëª¨ë‹ˆí„°ë§
watch -n 1 'intel_gpu_top'

# NVIDIA GPU ëª¨ë‹ˆí„°ë§
watch -n 1 'nvidia-smi'
```

## ğŸš€ ê³ ê¸‰ ì„¤ì • ë° ìµœì í™”

### Intel GPU ìµœì í™”

```bash
# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
export USE_INTEL_GPU=1

# ì½”ë“œì—ì„œ ìµœì í™” í™œì„±í™”
import intel_extension_for_pytorch as ipex
model = ipex.optimize(model)
```

### ë°ì´í„° ì¦ê°• ë° ì „ì²˜ë¦¬ ìµœì í™”

```python
# ê³ ê¸‰ ì „ì²˜ë¦¬ ì˜µì…˜
python main.py preprocess \
    --data_dir ./aihub_data \
    --output_dir ./processed_data \
    --sequence_length 64 \      # ë” ê¸´ ì‹œí€€ìŠ¤
    --overlap_ratio 0.5 \       # ì˜¤ë²„ë© ì¦ê°€
    --augment_data \           # ë°ì´í„° ì¦ê°• í™œì„±í™”
    --normalize_landmarks      # ëœë“œë§ˆí¬ ì •ê·œí™”
```

### ë¶„ì‚° í›ˆë ¨ ì„¤ì •

```bash
# ë‹¤ì¤‘ GPU í›ˆë ¨
python -m torch.distributed.launch \
    --nproc_per_node=2 \
    main.py train \
    --distributed \
    --batch_size 32
```

## ğŸ“ ì¶œë ¥ íŒŒì¼ êµ¬ì¡°

```
korean-sign-language-recognition/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ processed_data/
â”‚   â”‚   â”œâ”€â”€ train_data.pt           # í›ˆë ¨ ë°ì´í„°
â”‚   â”‚   â”œâ”€â”€ val_data.pt             # ê²€ì¦ ë°ì´í„°
â”‚   â”‚   â””â”€â”€ vocab.json              # ì–´íœ˜ ì‚¬ì „
â”‚   â”œâ”€â”€ trained_models/
â”‚   â”‚   â”œâ”€â”€ best_model.pt           # ìµœê³  ì„±ëŠ¥ ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ final_model.pt          # ìµœì¢… ëª¨ë¸
â”‚   â”‚   â”œâ”€â”€ training_history.json   # í›ˆë ¨ ì´ë ¥
â”‚   â”‚   â””â”€â”€ logs/                   # TensorBoard ë¡œê·¸
â”‚   â””â”€â”€ korean_sign_recognition.log # ëª¨ë¸ í›ˆë ¨ ë¡œê·¸ íŒŒì¼
â”‚
â””â”€â”€ server/
    â”œâ”€â”€ model.pt                    # í¬ì¦ˆ ì¶”ì • ëª¨ë¸
    â”œâ”€â”€ captured_videos/            # ë…¹í™”ëœ ë¹„ë””ì˜¤
    â”œâ”€â”€ captured_images/            # ìº¡ì²˜ëœ ì´ë¯¸ì§€
    â””â”€â”€ captured_datas/             # ì—°ì† ìº¡ì²˜ ë°ì´í„°
```

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì„¤ì¹˜ í™•ì¸
- [ ] Python 3.8+ ì„¤ì¹˜
- [ ] conda/venv í™˜ê²½ ìƒì„±
- [ ] model íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] server íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] Intel GPU/CUDA ì„¤ì • (ì„ íƒ)

### ë°ì´í„° ì¤€ë¹„
- [ ] AIHub ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
- [ ] ë°ì´í„° êµ¬ì¡° í™•ì¸
- [ ] ì „ì²˜ë¦¬ ì‹¤í–‰ ì™„ë£Œ
- [ ] train/val ë°ì´í„° ìƒì„± í™•ì¸

### ëª¨ë¸ í›ˆë ¨
- [ ] ê¸°ë³¸ í›ˆë ¨ ì‹¤í–‰ ì„±ê³µ
- [ ] best_model.pt ìƒì„± í™•ì¸
- [ ] í›ˆë ¨ ë¡œê·¸ í™•ì¸
- [ ] ì„±ëŠ¥ ì§€í‘œ í™•ì¸

### ì„œë²„ ë°°í¬
- [ ] RTMW ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
- [ ] MMPose ì„¤ì • ì™„ë£Œ
- [ ] í´ë˜ìŠ¤ ë§¤í•‘ ì„¤ì •
- [ ] ì„œë²„ ì‹¤í–‰ ì„±ê³µ
- [ ] ì›¹ìº  ì—°ê²° í™•ì¸

### í…ŒìŠ¤íŠ¸
- [ ] ì½˜ì†” í´ë¼ì´ì–¸íŠ¸ ë™ì‘ í™•ì¸
- [ ] ì›¹ ì¸í„°í˜ì´ìŠ¤ ì ‘ì† í™•ì¸
- [ ] ì‹¤ì‹œê°„ ìˆ˜ì–´ ì¸ì‹ í…ŒìŠ¤íŠ¸
- [ ] API ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸

## ğŸ¤ ê¸°ì—¬ ë°©ë²•

1. **ì´ìŠˆ ë¦¬í¬íŠ¸**: ë²„ê·¸ë‚˜ ê°œì„ ì‚¬í•­ ì œì•ˆ
2. **ì½”ë“œ ê¸°ì—¬**: Pull Request í™˜ì˜
3. **ë°ì´í„°ì…‹ ê¸°ì—¬**: ì¶”ê°€ ìˆ˜ì–´ ë°ì´í„° ì œê³µ
4. **ë¬¸ì„œ ê°œì„ **: READMEë‚˜ ì£¼ì„ ê°œì„ 
5. **ì„±ëŠ¥ ìµœì í™”**: ì•Œê³ ë¦¬ì¦˜ ê°œì„  ì œì•ˆ

### ê°œë°œ ê°€ì´ë“œë¼ì¸

- ì½”ë“œ ìŠ¤íƒ€ì¼: PEP 8 ì¤€ìˆ˜
- ì»¤ë°‹ ë©”ì‹œì§€: Conventional Commits í˜•ì‹
- í…ŒìŠ¤íŠ¸: ì£¼ìš” ê¸°ëŠ¥ì— ëŒ€í•œ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í¬í•¨
- ë¬¸ì„œ: ìƒˆë¡œìš´ ê¸°ëŠ¥ì— ëŒ€í•œ ë¬¸ì„œ ì—…ë°ì´íŠ¸

## ğŸ“„ ë¼ì´ì„ ìŠ¤

ë³¸ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤.

### ë°ì´í„°ì…‹ ë¼ì´ì„ ìŠ¤

- **AI Hub ìˆ˜ì–´ ì˜ìƒ ë°ì´í„°ì…‹**
  - ì œê³µ: í•œêµ­ì§€ëŠ¥ì •ë³´ì‚¬íšŒì§„í¥ì› (NIA)
  - ì—°ë„: 2021
  - ìš©ë„: ì—°êµ¬ ë° êµìœ¡ ëª©ì 
  - ìƒì—…ì  ì‚¬ìš© ì‹œ ë³„ë„ ë¼ì´ì„ ìŠ¤ í™•ì¸ í•„ìš”

## ğŸ“ ì§€ì› ë° ì—°ë½ì²˜

- **GitHub Issues**: ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ê¸°ëŠ¥ ìš”ì²­
- **ì´ë©”ì¼**: [ê°œë°œì ì´ë©”ì¼]
- **ìœ„í‚¤**: [í”„ë¡œì íŠ¸ ìœ„í‚¤ ë§í¬]
- **ë°ëª¨**: [ì˜¨ë¼ì¸ ë°ëª¨ ë§í¬]

## ğŸ“š ì°¸ê³ ë¬¸í—Œ

1. AI Hub ìˆ˜ì–´ ì˜ìƒ ë°ì´í„°ì…‹ (í•œêµ­ì§€ëŠ¥ì •ë³´ì‚¬íšŒì§„í¥ì›, 2021)
2. OpenHands: Making Sign Language Recognition Accessible (arXiv preprint)
3. MediaPipe Hands: On-device Real-time Hand Tracking (Google AI)
4. Real-Time Multi-Person 2D Pose Estimation using Part Affinity Fields
5. YOLOv11: An Improved Version of YOLO for Object Detection

---

**ì£¼ì˜ì‚¬í•­**: ë³¸ ì‹œìŠ¤í…œì€ ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ì„œë¹„ìŠ¤ ë°°í¬ ì‹œì—ëŠ” ì„±ëŠ¥ ìµœì í™” ë° ë³´ì•ˆ ê°•í™”ê°€ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
