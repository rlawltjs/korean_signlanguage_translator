import cv2
import os
import time
import datetime
import glob
import requests
import json
import numpy as np
import threading
from collections import deque

# COCO Wholebody ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²° ì •ë³´
COCO_WHOLEBODY_SKELETON = [
    # Body (0~16)
    [0, 1], [0, 2], [1, 3], [2, 4],
    [5, 6], [5, 7], [7, 9], [6, 8], [8, 10],
    [5, 11], [6, 12], [11, 12], [11, 13], [13, 15], [12, 14], [14, 16],

    # Left Hand (91~111)
    [91, 92], [92, 93], [93, 94], [94, 95],         # Thumb
    [91, 96], [96, 97], [97, 98], [98, 99],         # Index
    [91, 100], [100, 101], [101, 102], [102, 103],  # Middle
    [91, 104], [104, 105], [105, 106], [106, 107],  # Ring
    [91, 108], [108, 109], [109, 110], [110, 111],  # Pinky

    # Right Hand (112~132)
    [112, 113], [113, 114], [114, 115], [115, 116],      # Thumb
    [112, 117], [117, 118], [118, 119], [119, 120],      # Index
    [112, 121], [121, 122], [122, 123], [123, 124],      # Middle
    [112, 125], [125, 126], [126, 127], [127, 128],      # Ring
    [112, 129], [129, 130], [130, 131], [131, 132],      # Pinky
]

def draw_keypoints_wholebody_on_frame(frame, keypoints, scores, threshold=2.0):
    """í”„ë ˆì„ì— wholebody í‚¤í¬ì¸íŠ¸ì™€ ìŠ¤ì¼ˆë ˆí†¤ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜ (ì„œë²„ì—ì„œ ì´ë¯¸ ì¢Œí‘œ ë³€í™˜ë¨)"""
    num_points = 133
    
    print(f"ğŸ”§ ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì‹œì‘")
    print(f"  - í”„ë ˆì„ í¬ê¸°: {frame.shape[1]}x{frame.shape[0]}")
    print(f"  - í‚¤í¬ì¸íŠ¸ ê°œìˆ˜: {len(keypoints)}")
    print(f"  - ìŠ¤ì½”ì–´ ê°œìˆ˜: {len(scores)}")

    # í‚¤í¬ì¸íŠ¸ ê·¸ë¦¬ê¸° (ì„œë²„ì—ì„œ ì´ë¯¸ ì›ë³¸ ì´ë¯¸ì§€ ì¢Œí‘œë¡œ ë³€í™˜ë¨)
    drawn_points = 0
    for idx in range(min(num_points, len(keypoints), len(scores))):
        if 17 <= idx <= 22:  # ë°œ keypoint ë¬´ì‹œ
            continue
        if scores[idx] > threshold:
            x, y = keypoints[idx][:2]
            # í”„ë ˆì„ ê²½ê³„ í™•ì¸
            if 0 <= x < frame.shape[1] and 0 <= y < frame.shape[0]:
                cv2.circle(frame, (int(x), int(y)), 3, (0, 255, 0), -1)
                drawn_points += 1

    print(f"âœ… ê·¸ë ¤ì§„ í‚¤í¬ì¸íŠ¸: {drawn_points}ê°œ")

    # ìŠ¤ì¼ˆë ˆí†¤ ì—°ê²°ì„  ê·¸ë¦¬ê¸°
    drawn_lines = 0
    for idx1, idx2 in COCO_WHOLEBODY_SKELETON:
        if 17 <= idx1 <= 22 or 17 <= idx2 <= 22:  # ë°œ keypoint í¬í•¨ëœ ì—°ê²° ë¬´ì‹œ
            continue
        if (idx1 < len(scores) and idx2 < len(scores) and 
            scores[idx1] > threshold and scores[idx2] > threshold):
            x1, y1 = keypoints[idx1][:2]
            x2, y2 = keypoints[idx2][:2]
            
            # í”„ë ˆì„ ê²½ê³„ í™•ì¸
            if (0 <= x1 < frame.shape[1] and 0 <= y1 < frame.shape[0] and
                0 <= x2 < frame.shape[1] and 0 <= y2 < frame.shape[0]):
                cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (255, 0, 0), 2)
                drawn_lines += 1
    
    print(f"âœ… ê·¸ë ¤ì§„ ì—°ê²°ì„ : {drawn_lines}ê°œ")

def draw_sign_prediction_on_frame(frame, prediction_text, confidence, x=10, y=30):
    """í”„ë ˆì„ì— ìˆ˜ì–´ ì¸ì‹ ê²°ê³¼ë¥¼ ê·¸ë¦¬ëŠ” í•¨ìˆ˜"""
    if prediction_text:
        # ë°°ê²½ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
        text = f"Sign: {prediction_text} ({confidence:.2f})"
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.8
        thickness = 2
        
        (text_width, text_height), baseline = cv2.getTextSize(text, font, font_scale, thickness)
        
        # ë°°ê²½ ì‚¬ê°í˜•
        cv2.rectangle(frame, (x-5, y-text_height-10), (x+text_width+5, y+baseline+5), (0, 0, 0), -1)
        
        # í…ìŠ¤íŠ¸
        color = (0, 255, 0) if confidence > 0.7 else (0, 255, 255) if confidence > 0.5 else (0, 0, 255)
        cv2.putText(frame, text, (x, y), font, font_scale, color, thickness)

class WebcamCapture:
    """ì›¹ìº  ìº¡ì²˜ ë° ì‹¤ì‹œê°„ ì²˜ë¦¬ í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, server_url="http://000.000.000.000:5000"):
        self.cap = None
        self.recording = False
        self.video_writer = None
        self.capturing_images = False
        self.realtime_translate = False
        self.realtime_fps = 0
        self.capture_folder = None
        self.capture_image_count = 0
        self.video_folder = "./captured_videos"
        self.image_folder = "./captured_images"
        self.video_count = 0
        self.image_count = 0
        self.w = 640
        self.h = 480
        self.fps = 10
        self.last_server_result = ""
        self.server_url = server_url
        
        # ìŠ¤ì¼ˆë ˆí†¤ ì‹œê°í™” ê´€ë ¨ ë³€ìˆ˜ë“¤
        self.show_skeleton = False
        self.last_pose_data = None  # ë§ˆì§€ë§‰ í¬ì¦ˆ ë°ì´í„° ì €ì¥
        self.pose_threshold = 2.0

        # ìˆ˜ì–´ ì¸ì‹ ê´€ë ¨ ë³€ìˆ˜ë“¤
        self.sign_recognition_mode = False
        self.show_sign_prediction = False
        self.last_sign_prediction = ""
        self.last_sign_confidence = 0.0
        self.sign_confidence_threshold = 0.6
        self.client_id = f"webcam_{int(time.time())}"
        
        # ìˆ˜ì–´ ì¸ì‹ ì˜ˆì¸¡ ê²°ê³¼ í‰í™œí™”ë¥¼ ìœ„í•œ ë²„í¼
        self.sign_prediction_buffer = deque(maxlen=5)
        self.sign_smoothing_enabled = True

        # í´ë” ìƒì„±
        os.makedirs(self.video_folder, exist_ok=True)
        os.makedirs(self.image_folder, exist_ok=True)

    def initialize_camera(self):
        """ì¹´ë©”ë¼ ì´ˆê¸°í™”"""
        if self.cap is None or not self.cap.isOpened():
            self.cap = cv2.VideoCapture(0)
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, self.w)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, self.h)
            self.fps = self.cap.get(cv2.CAP_PROP_FPS) or 30
        return self.cap.isOpened()
    
    def release_camera(self):
        """ì¹´ë©”ë¼ í•´ì œ"""
        if self.cap:
            self.cap.release()
            self.cap = None
        if self.video_writer:
            self.video_writer.release()
            self.video_writer = None
    
    def toggle_skeleton_display(self):
        """ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ í† ê¸€"""
        self.show_skeleton = not self.show_skeleton
        status = f"ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ: {'ì¼œì§' if self.show_skeleton else 'êº¼ì§'}"
        print(f"ğŸ”§ {status}")
        return status
    
    def toggle_sign_recognition(self):
        """ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ í† ê¸€ (ìˆ˜ì •ë¨ - í¬ì¦ˆ ì¶”ì •ê³¼ ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥)"""
        self.sign_recognition_mode = not self.sign_recognition_mode
        if self.sign_recognition_mode:
            # ê¸°ì¡´ì˜ í¬ì¦ˆ ì¶”ì • ê°•ì œ ì¢…ë£Œ ì½”ë“œ ì œê±°
            # self.realtime_translate = False  # ì´ ì¤„ì„ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì œê±°
            self.clear_sign_buffer()
        status = f"ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ: {'ì¼œì§' if self.sign_recognition_mode else 'êº¼ì§'}"
        print(f"ğŸ¤Ÿ {status}")
        return status
    
    def toggle_sign_prediction_display(self):
        """ìˆ˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ í† ê¸€"""
        self.show_sign_prediction = not self.show_sign_prediction
        status = f"ìˆ˜ì–´ ì˜ˆì¸¡ í‘œì‹œ: {'ì¼œì§' if self.show_sign_prediction else 'êº¼ì§'}"
        print(f"ğŸ¯ {status}")
        return status
    
    def toggle_sign_smoothing(self):
        """ìˆ˜ì–´ ì˜ˆì¸¡ í‰í™œí™” í† ê¸€"""
        self.sign_smoothing_enabled = not self.sign_smoothing_enabled
        if not self.sign_smoothing_enabled:
            self.sign_prediction_buffer.clear()
        status = f"ìˆ˜ì–´ ì˜ˆì¸¡ í‰í™œí™”: {'ì¼œì§' if self.sign_smoothing_enabled else 'êº¼ì§'}"
        print(f"ğŸ“Š {status}")
        return status
    
    def set_pose_threshold(self, threshold):
        """í¬ì¦ˆ ì„ê³„ê°’ ì„¤ì •"""
        self.pose_threshold = threshold
        return f"í¬ì¦ˆ ì„ê³„ê°’: {threshold}"
    
    def set_sign_confidence_threshold(self, threshold):
        """ìˆ˜ì–´ ì¸ì‹ ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì •"""
        self.sign_confidence_threshold = threshold
        return f"ìˆ˜ì–´ ì‹ ë¢°ë„ ì„ê³„ê°’: {threshold}"
    
    def clear_sign_buffer(self):
        """ì„œë²„ì˜ ìˆ˜ì–´ íŠ¹ì§• ë²„í¼ í´ë¦¬ì–´"""
        try:
            response = requests.post(f"{self.server_url}/clear_buffer/{self.client_id}", timeout=5)
            if response.status_code == 200:
                print(f"âœ… ìˆ˜ì–´ ë²„í¼ í´ë¦¬ì–´ë¨: {self.client_id}")
            self.sign_prediction_buffer.clear()
            self.last_sign_prediction = ""
            self.last_sign_confidence = 0.0
        except Exception as e:
            print(f"âŒ ìˆ˜ì–´ ë²„í¼ í´ë¦¬ì–´ ì‹¤íŒ¨: {e}")
    
    def start_realtime(self):
        """ì´ë¯¸ì§€ ì‹¤ì‹œê°„ ë²ˆì—­ ì‹œì‘ (ê¸°ì¡´ í¬ì¦ˆ ì¶”ì •)"""
        if not self.realtime_translate:
            self.realtime_translate = True
            self.realtime_fps = 0
            self.last_server_result = ""
            # ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ ë¹„í™œì„±í™”
            # self.sign_recognition_mode = False
            return f"ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • ì‹œì‘"
        return "ì´ë¯¸ ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • ì¤‘ì…ë‹ˆë‹¤"

    def stop_realtime(self):
        """ì´ë¯¸ì§€ ì‹¤ì‹œê°„ ë²ˆì—­ ì¢…ë£Œ"""
        if self.realtime_translate:
            self.realtime_translate = False
            self.realtime_fps = 0
            return f"ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • ì¢…ë£Œ"
        return "ì´ë¯¸ ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤."

    def start_capture_images(self):
        """ì´ë¯¸ì§€ ì—°ì† ì €ì¥ ì‹œì‘"""
        if not self.capturing_images:
            now = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
            self.capture_folder = os.path.join("captured_datas", now)
            os.makedirs(self.capture_folder, exist_ok=True)
            self.capturing_images = True
            self.capture_image_count = 0
            return f"ì´ë¯¸ì§€ ìº¡ì²˜ ì‹œì‘: {self.capture_folder}"
        return "ì´ë¯¸ ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘ì…ë‹ˆë‹¤"

    def stop_capture_images(self):
        """ì´ë¯¸ì§€ ì—°ì† ì €ì¥ ì¢…ë£Œ"""
        if self.capturing_images:
            self.capturing_images = False
            folder = self.capture_folder
            self.capture_folder = None
            return f"ì´ë¯¸ì§€ ìº¡ì²˜ ì¢…ë£Œ: {folder}"
        return "ì´ë¯¸ì§€ ìº¡ì²˜ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤"

    def capture_frame(self):
        """í”„ë ˆì„ ìº¡ì²˜"""
        if not self.initialize_camera():
            return None

        ret, frame = self.cap.read()
        if ret:
            # ì‹¤ì‹œê°„ ëª¨ë“œì— ë”°ë¥¸ ì„œë²„ ìš”ì²­
            if self.realtime_translate:
                self.send_frame_for_pose_estimation(frame)
            if self.sign_recognition_mode:
                self.send_frame_for_sign_recognition(frame)
            
            # í˜„ì¬ ìƒíƒœ ì¶œë ¥ (ë§¤ 30í”„ë ˆì„ë§ˆë‹¤)
            if self.realtime_fps % 30 == 0:
                print(f"ğŸ“Š í˜„ì¬ ìƒíƒœ - í¬ì¦ˆì¶”ì •: {self.realtime_translate}, ìˆ˜ì–´ì¸ì‹: {self.sign_recognition_mode}, "
                      f"ìŠ¤ì¼ˆë ˆí†¤í‘œì‹œ: {self.show_skeleton}, ìˆ˜ì–´í‘œì‹œ: {self.show_sign_prediction}")
            
            # ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œê°€ í™œì„±í™”ë˜ì–´ ìˆê³  í¬ì¦ˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ë¦¬ê¸°
            if self.show_skeleton and self.last_pose_data:
                try:
                    keypoints = self.last_pose_data.get('keypoints', [])
                    scores = self.last_pose_data.get('scores', [])
                    
                    if keypoints and scores:
                        draw_keypoints_wholebody_on_frame(
                            frame, keypoints, scores, self.pose_threshold
                        )
                except Exception as e:
                    print(f"ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
            
            # ìˆ˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ í‘œì‹œ
            if self.show_sign_prediction and self.last_sign_prediction:
                try:
                    draw_sign_prediction_on_frame(
                        frame, self.last_sign_prediction, self.last_sign_confidence
                    )
                except Exception as e:
                    print(f"ìˆ˜ì–´ ì˜ˆì¸¡ í‘œì‹œ ì˜¤ë¥˜: {e}")
            
            # ë…¹í™” ì¤‘ì´ë©´ ë¹„ë””ì˜¤ì— ì €ì¥
            if self.recording and self.video_writer:
                self.video_writer.write(frame)
            # ì´ë¯¸ì§€ ì—°ì† ì €ì¥ ì¤‘ì´ë©´ íŒŒì¼ë¡œ ì €ì¥
            elif self.capturing_images and self.capture_folder:
                self.capture_image_count += 1
                image_path = os.path.join(
                    self.capture_folder, f"img_{self.capture_image_count:04d}.jpg"
                )
                cv2.imwrite(image_path, frame)

            return frame
        return None
    
    def save_image(self, save_skeleton=False, save_sign=False):
        """ì´ë¯¸ì§€ ì €ì¥"""
        if not self.initialize_camera():
            return None
        
        ret, frame = self.cap.read()
        if ret:
            # ìŠ¤ì¼ˆë ˆí†¤ ì €ì¥ ì˜µì…˜ì´ í™œì„±í™”ë˜ì–´ ìˆê³  í¬ì¦ˆ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ë¦¬ê¸°
            if save_skeleton and self.last_pose_data:
                try:
                    keypoints = self.last_pose_data.get('keypoints', [])
                    scores = self.last_pose_data.get('scores', [])
                    
                    if keypoints and scores:
                        draw_keypoints_wholebody_on_frame(
                            frame, keypoints, scores, self.pose_threshold
                        )
                except Exception as e:
                    print(f"ìŠ¤ì¼ˆë ˆí†¤ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
            
            # ìˆ˜ì–´ ì˜ˆì¸¡ ì €ì¥ ì˜µì…˜
            if save_sign and self.last_sign_prediction:
                try:
                    draw_sign_prediction_on_frame(
                        frame, self.last_sign_prediction, self.last_sign_confidence
                    )
                except Exception as e:
                    print(f"ìˆ˜ì–´ ì˜ˆì¸¡ ê·¸ë¦¬ê¸° ì˜¤ë¥˜: {e}")
    
    def start_recording(self):
        """ë¹„ë””ì˜¤ ë…¹í™” ì‹œì‘"""
        if not self.recording:
            self.video_count += 1
            video_path = f"{self.video_folder}/record_{self.video_count}.avi"
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            self.video_writer = cv2.VideoWriter(video_path, fourcc, self.fps, (self.w, self.h))
            self.recording = True
            return f"ë…¹í™” ì‹œì‘: {video_path}"
        return "ì´ë¯¸ ë…¹í™” ì¤‘ì…ë‹ˆë‹¤"
    
    def stop_recording(self):
        """ë¹„ë””ì˜¤ ë…¹í™” ì¢…ë£Œ"""
        if self.recording:
            self.recording = False
            if self.video_writer:
                self.video_writer.release()
                self.video_writer = None
            return "ë…¹í™” ì¢…ë£Œ"
        return "ë…¹í™” ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤"
    
    def generate_frames(self):
        """ìŠ¤íŠ¸ë¦¬ë°ìš© í”„ë ˆì„ ìƒì„±"""
        # fpsê°€ 0ì´ê±°ë‚˜ Noneì´ë©´ ê¸°ë³¸ê°’ 30fps ì‚¬ìš©
        fps = self.fps if self.fps and self.fps > 0 else 30
        target_interval = 1.0 / fps

        while True:
            start = time.time()
            frame = self.capture_frame()
            if frame is not None:
                # JPEGë¡œ ì¸ì½”ë”©
                ret, buffer = cv2.imencode('.jpg', frame)
                if ret:
                    frame_bytes = buffer.tobytes()
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            elapsed = time.time() - start
            sleep_time = max(0, target_interval - elapsed)
            if sleep_time > 0:
                time.sleep(sleep_time)

    def send_frame_for_pose_estimation(self, frame):
        """ì„œë²„ë¡œ ì›ë³¸ í”„ë ˆì„ ì „ì†¡ (í¬ì¦ˆ ì¶”ì •ìš©)"""
        self.realtime_fps += 1 
        
        # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            print("âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
            return
            
        frame_bytes = buffer.tobytes()
        
        try:
            print(f"ğŸ“¤ ì„œë²„ë¡œ í¬ì¦ˆ ì¶”ì • ì´ë¯¸ì§€ ì „ì†¡")
            
            files = {'image': (f'{self.realtime_fps}.jpg', frame_bytes, 'image/jpeg')}
            data = {'frame_id': str(self.realtime_fps)}
            
            resp = requests.post(
                f"{self.server_url}/estimate_pose",
                files=files,
                data=data,
                timeout=10
            )
            
            # ì„œë²„ ì‘ë‹µ ì²˜ë¦¬ ë° í¬ì¦ˆ ë°ì´í„° ì €ì¥
            if resp.status_code == 200:
                print("âœ… í¬ì¦ˆ ì¶”ì • ì„œë²„ ì „ì†¡ ì„±ê³µ")
                try:
                    response_data = resp.json()
                    
                    if 'error' in response_data:
                        print(f"âš ï¸ ì„œë²„ ì˜¤ë¥˜: {response_data['error']}")
                        return
                    
                    keypoints = response_data.get('keypoints', [])
                    scores = response_data.get('scores', [])
                    person_box = response_data.get('person_box', [])
                    
                    if keypoints and scores:
                        self.last_pose_data = {
                            'keypoints': keypoints,
                            'scores': scores,
                            'person_box': person_box
                        }
                        print(f"âœ… í¬ì¦ˆ ë°ì´í„° ì—…ë°ì´íŠ¸ë¨!")
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                except Exception as e:
                    print(f"âŒ ì„œë²„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            else:
                print(f"âŒ í¬ì¦ˆ ì¶”ì • ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {resp.status_code}")
                
            self.last_server_result = f"{self.realtime_fps}-í¬ì¦ˆì¶”ì •ê²°ê³¼"
            
        except Exception as e:
            print(f"âŒ í¬ì¦ˆ ì¶”ì • ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

    def send_frame_for_sign_recognition(self, frame):
        """ì„œë²„ë¡œ ì›ë³¸ í”„ë ˆì„ ì „ì†¡ (ìˆ˜ì–´ ì¸ì‹ìš©)"""
        self.realtime_fps += 1
        
        # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
        ret, buffer = cv2.imencode('.jpg', frame)
        if not ret:
            print("âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨")
            return
            
        frame_bytes = buffer.tobytes()
        
        try:
            print(f"ğŸ¤Ÿ ì„œë²„ë¡œ ìˆ˜ì–´ ì¸ì‹ ì´ë¯¸ì§€ ì „ì†¡")
            
            files = {'image': (f'{self.realtime_fps}.jpg', frame_bytes, 'image/jpeg')}
            data = {
                'frame_id': str(self.realtime_fps),
                'client_id': self.client_id,
                'confidence_threshold': str(self.sign_confidence_threshold),
                'extract_only': 'false'
            }
            
            resp = requests.post(
                f"{self.server_url}/sign_recognition",
                files=files,
                data=data,
                timeout=10
            )
            
            # ì„œë²„ ì‘ë‹µ ì²˜ë¦¬
            if resp.status_code == 200:
                print("âœ… ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì „ì†¡ ì„±ê³µ")
                try:
                    response_data = resp.json()
                    
                    if 'error' in response_data:
                        print(f"âš ï¸ ì„œë²„ ì˜¤ë¥˜: {response_data['error']}")
                        return
                    
                    # ìˆ˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
                    sign_predictions = response_data.get('sign_predictions', [])
                    buffer_length = response_data.get('buffer_length', 0)
                    sequence_required = response_data.get('sequence_length_required', 32)
                    
                    print(f"ğŸ“Š ìˆ˜ì–´ ë²„í¼ ìƒíƒœ: {buffer_length}/{sequence_required}")
                    
                    if sign_predictions:
                        best_prediction = sign_predictions[0]
                        pred_word = best_prediction['word']
                        pred_confidence = best_prediction['confidence']
                        
                        print(f"ğŸ¯ ìˆ˜ì–´ ì˜ˆì¸¡: {pred_word} (ì‹ ë¢°ë„: {pred_confidence:.2f})")
                        
                        # í‰í™œí™” ì²˜ë¦¬
                        if self.sign_smoothing_enabled:
                            self.sign_prediction_buffer.append({
                                'word': pred_word,
                                'confidence': pred_confidence
                            })
                            self.smooth_sign_predictions()
                        else:
                            # í‰í™œí™” ì—†ì´ ì§ì ‘ ì—…ë°ì´íŠ¸
                            if pred_confidence >= self.sign_confidence_threshold:
                                self.last_sign_prediction = pred_word
                                self.last_sign_confidence = pred_confidence
                    else:
                        print("â³ ìˆ˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ ì—†ìŒ")
                        
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
                except Exception as e:
                    print(f"âŒ ì„œë²„ ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {e}")
            else:
                print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {resp.status_code}")
                
        except Exception as e:
            print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {e}")

    def smooth_sign_predictions(self):
        """ìˆ˜ì–´ ì˜ˆì¸¡ ê²°ê³¼ í‰í™œí™”"""
        if not self.sign_prediction_buffer:
            return
        
        # ë‹¨ì–´ë³„ ì‹ ë¢°ë„ ì ìˆ˜ ì§‘ê³„
        word_scores = {}
        for pred in self.sign_prediction_buffer:
            word = pred['word']
            confidence = pred['confidence']
            
            if word in word_scores:
                word_scores[word].append(confidence)
            else:
                word_scores[word] = [confidence]
        
        # ê° ë‹¨ì–´ì˜ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        word_avg_scores = {}
        for word, scores in word_scores.items():
            word_avg_scores[word] = np.mean(scores)
        
        if word_avg_scores:
            # ê°€ì¥ ë†’ì€ í‰ê·  ì‹ ë¢°ë„ë¥¼ ê°€ì§„ ë‹¨ì–´ ì„ íƒ
            best_word, best_confidence = max(word_avg_scores.items(), key=lambda x: x[1])
            
            # ì„ê³„ê°’ ì´ìƒì´ê³  ê¸°ì¡´ ì˜ˆì¸¡ê³¼ ë‹¤ë¥´ë©´ ì—…ë°ì´íŠ¸
            if best_confidence >= self.sign_confidence_threshold:
                if self.last_sign_prediction != best_word:
                    print(f"ğŸ¯ í‰í™œí™”ëœ ìˆ˜ì–´ ì˜ˆì¸¡: {best_word} (ì‹ ë¢°ë„: {best_confidence:.2f})")
                    self.last_sign_prediction = best_word
                    self.last_sign_confidence = best_confidence

    def process_latest_folder_images(self):
        """ê°€ì¥ ìµœê·¼ í´ë”ì˜ ì´ë¯¸ì§€ë¥¼ ì„œë²„ë¡œ ì „ì†¡ (í¬ì¦ˆ ì¶”ì •ìš©)"""
        base_dir = "captured_datas"
        if not os.path.exists(base_dir):
            return "ì €ì¥ëœ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        folders = [os.path.join(base_dir, d) for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]
        if not folders:
            return "ì €ì¥ëœ í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        latest_folder = max(folders, key=os.path.getmtime)
        images = sorted(glob.glob(os.path.join(latest_folder, "*.jpg")))
        send_count = 0
        
        for img_path in images:
            frame = cv2.imread(img_path)
            if frame is None:
                continue
            
            # ì´ë¯¸ì§€ë¥¼ JPEGë¡œ ì¸ì½”ë”©
            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                print(f"âŒ ì´ë¯¸ì§€ ì¸ì½”ë”© ì‹¤íŒ¨: {img_path}")
                continue
            
            image_bytes = buffer.tobytes()
            
            # ì„œë²„ë¡œ ì „ì†¡
            try:
                files = {'image': (os.path.basename(img_path), image_bytes, 'image/jpeg')}
                data = {'frame_id': os.path.basename(img_path)}
                
                resp = requests.post(
                    f"{self.server_url}/estimate_pose",
                    files=files,
                    data=data,
                    timeout=10
                )
                
                if resp.status_code == 200:
                    send_count += 1
                    print(f"âœ… ì„œë²„ë¡œ ì „ì†¡ ì„±ê³µ: {send_count}, {img_path}")
                else:
                    print(f"âŒ ì„œë²„ ì‘ë‹µ ì˜¤ë¥˜: {resp.status_code} {resp.text}")
                    
            except Exception as e:
                print(f"âŒ ì„œë²„ ì „ì†¡ ì‹¤íŒ¨: {os.path.basename(img_path)} - {e}")
        
        return f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì™„ë£Œ: {len(images)}ê°œ ì´ë¯¸ì§€ ì¤‘ {send_count}ê°œ ì„œë²„ ì „ì†¡ ì„±ê³µ"

    def get_server_stats(self):
        """ì„œë²„ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        try:
            resp = requests.get(f"{self.server_url}/stats", timeout=5)
            if resp.status_code == 200:
                stats = resp.json()
                print("\nğŸ“Š ì„œë²„ í†µê³„:")
                print(f"  - í¬ì¦ˆ ì¶”ì • ìš”ì²­: {stats.get('request_count', 0)}")
                print(f"  - ìˆ˜ì–´ ì¸ì‹ ìš”ì²­: {stats.get('sign_request_count', 0)}")
                print(f"  - ìˆ˜ì–´ ëª¨ë¸ ë¡œë“œë¨: {stats.get('sign_model_loaded', False)}")
                print(f"  - í™œì„± í´ë¼ì´ì–¸íŠ¸: {stats.get('active_clients', 0)}")
                print(f"  - í‰ê·  ì²˜ë¦¬ì‹œê°„: {stats.get('processing_times', {}).get('mean', 0)*1000:.1f}ms")
                print(f"  - í‰ê·  ìˆ˜ì–´ ì²˜ë¦¬ì‹œê°„: {stats.get('sign_processing_times', {}).get('mean', 0)*1000:.1f}ms")
                return stats
            else:
                print(f"âŒ ì„œë²„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {resp.status_code}")
        except Exception as e:
            print(f"âŒ ì„œë²„ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None

    def recognize_sign_sequence(self, features, confidence_threshold=0.6):
        """ìˆ˜ì–´ ì‹œí€€ìŠ¤ ì¸ì‹"""
        if not self.recognizer or not self.recognizer.sign_model:
            return {
                'predictions': [],
                'message': 'Sign recognition model not loaded',
                'has_model': False
            }
        
        try:
            return self.recognizer.predict_sign_sequence(features, confidence_threshold)
        except Exception as e:
            print(f"âŒ ìˆ˜ì–´ ì¸ì‹ ì‹¤íŒ¨: {e}")
            return {
                'predictions': [],
                'message': f'Recognition failed: {str(e)}',
                'has_model': True
            }

# ì‚¬ìš© ì˜ˆì‹œ ë° í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤ ì•ˆë‚´
def print_usage():
    """ì‚¬ìš©ë²• ì¶œë ¥"""
    print("\n" + "="*60)
    print("ğŸ¥ Enhanced Webcam with Pose Estimation & Sign Recognition")
    print("="*60)
    print("ê¸°ë³¸ ì¡°ì‘:")
    print("  q: ì¢…ë£Œ")
    print("  r: ë…¹í™” ì‹œì‘/ì¤‘ì§€")
    print("  c: ì´ë¯¸ì§€ ìº¡ì²˜")
    print("  i: ì—°ì† ì´ë¯¸ì§€ ì €ì¥ ì‹œì‘/ì¤‘ì§€")
    print("")
    print("í¬ì¦ˆ ì¶”ì •:")
    print("  p: ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • í† ê¸€")
    print("  s: ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ í† ê¸€")
    print("  1~5: í¬ì¦ˆ ì„ê³„ê°’ ì„¤ì • (1.0~5.0)")
    print("")
    print("ìˆ˜ì–´ ì¸ì‹:")
    print("  g: ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ í† ê¸€")
    print("  d: ìˆ˜ì–´ ì˜ˆì¸¡ í‘œì‹œ í† ê¸€")
    print("  f: ìˆ˜ì–´ ì˜ˆì¸¡ í‰í™œí™” í† ê¸€")
    print("  6~9: ìˆ˜ì–´ ì‹ ë¢°ë„ ì„ê³„ê°’ (0.3~0.9)")
    print("  x: ìˆ˜ì–´ ë²„í¼ í´ë¦¬ì–´")
    print("")
    print("ê¸°íƒ€:")
    print("  t: ì„œë²„ í†µê³„ ì¡°íšŒ")
    print("  h: ë„ì›€ë§ ì¬ì¶œë ¥")
    print("="*60)

if __name__ == "__main__":
    # ì›¹ìº  ìº¡ì²˜ ê°ì²´ ìƒì„±
    webcam = WebcamCapture()
    
    # ì‚¬ìš©ë²• ì¶œë ¥
    print_usage()
    
    try:
        # ì¹´ë©”ë¼ ì´ˆê¸°í™”
        if not webcam.initialize_camera():
            print("âŒ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨")
            exit(1)
        
        print("âœ… ì›¹ìº  ì‹œì‘ë¨. í‚¤ë³´ë“œë¡œ ì¡°ì‘í•˜ì„¸ìš”.")
        
        while True:
            frame = webcam.capture_frame()
            if frame is not None:
                cv2.imshow('Enhanced Webcam', frame)
            
            key = cv2.waitKey(1) & 0xFF
            
            # ì¢…ë£Œ
            if key == ord('q'):
                break
            # ë…¹í™” í† ê¸€
            elif key == ord('r'):
                if webcam.recording:
                    print(webcam.stop_recording())
                else:
                    print(webcam.start_recording())
            # ì´ë¯¸ì§€ ìº¡ì²˜
            elif key == ord('c'):
                webcam.save_image(save_skeleton=webcam.show_skeleton, save_sign=webcam.show_sign_prediction)
                print("ğŸ“· ì´ë¯¸ì§€ ì €ì¥ë¨")
            # ì—°ì† ì´ë¯¸ì§€ ì €ì¥ í† ê¸€
            elif key == ord('i'):
                if webcam.capturing_images:
                    print(webcam.stop_capture_images())
                else:
                    print(webcam.start_capture_images())
            # ì‹¤ì‹œê°„ í¬ì¦ˆ ì¶”ì • í† ê¸€
            elif key == ord('p'):
                if webcam.realtime_translate:
                    print(webcam.stop_realtime())
                else:
                    print(webcam.start_realtime())
            # ìŠ¤ì¼ˆë ˆí†¤ í‘œì‹œ í† ê¸€
            elif key == ord('s'):
                print(webcam.toggle_skeleton_display())
            # ìˆ˜ì–´ ì¸ì‹ ëª¨ë“œ í† ê¸€
            elif key == ord('g'):
                print(webcam.toggle_sign_recognition())
            # ìˆ˜ì–´ ì˜ˆì¸¡ í‘œì‹œ í† ê¸€
            elif key == ord('d'):
                print(webcam.toggle_sign_prediction_display())
            # ìˆ˜ì–´ ì˜ˆì¸¡ í‰í™œí™” í† ê¸€
            elif key == ord('f'):
                print(webcam.toggle_sign_smoothing())
            # ìˆ˜ì–´ ë²„í¼ í´ë¦¬ì–´
            elif key == ord('x'):
                webcam.clear_sign_buffer()
            # ì„œë²„ í†µê³„ ì¡°íšŒ
            elif key == ord('t'):
                webcam.get_server_stats()
            # ë„ì›€ë§
            elif key == ord('h'):
                print_usage()
            # í¬ì¦ˆ ì„ê³„ê°’ ì„¤ì • (1~5)
            elif key == ord('1'):
                print(webcam.set_pose_threshold(1.0))
            elif key == ord('2'):
                print(webcam.set_pose_threshold(2.0))
            elif key == ord('3'):
                print(webcam.set_pose_threshold(3.0))
            elif key == ord('4'):
                print(webcam.set_pose_threshold(4.0))
            elif key == ord('5'):
                print(webcam.set_pose_threshold(5.0))
            # ìˆ˜ì–´ ì‹ ë¢°ë„ ì„ê³„ê°’ ì„¤ì • (6~9)
            elif key == ord('6'):
                print(webcam.set_sign_confidence_threshold(0.3))
            elif key == ord('7'):
                print(webcam.set_sign_confidence_threshold(0.5))
            elif key == ord('8'):
                print(webcam.set_sign_confidence_threshold(0.7))
            elif key == ord('9'):
                print(webcam.set_sign_confidence_threshold(0.9))
    
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        webcam.release_camera()
        cv2.destroyAllWindows()
        print("ğŸ‘‹ ì›¹ìº  ì¢…ë£Œë¨")